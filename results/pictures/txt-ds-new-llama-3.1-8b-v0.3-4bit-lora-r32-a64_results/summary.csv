,count,mean,std,min,25%,50%,75%,max
answer_relevancy,1516.0,0.9603329296407467,0.12889598147439396,0.0,1.0,1.0,1.0,1.0
bert_f1,1516.0,0.8540044884175299,0.032221295527727234,0.5801416039466858,0.8389307409524918,0.8560113310813904,0.8729008287191391,0.992954432964325
bert_precision,1516.0,0.8710084114430133,0.03253811213832284,0.5914244651794434,0.8538781106472015,0.8723525106906891,0.8905373364686966,0.992954432964325
bert_recall,1516.0,0.8382986020444251,0.038755035757977674,0.5048511028289795,0.8196508586406708,0.8414667248725891,0.8609501421451569,0.992954432964325
bleu1,1516.0,0.19341403778487545,0.11777770811542679,0.0,0.10497344110409756,0.1849296465317319,0.2692713555015011,0.9130434782608695
bleu2,1516.0,0.10174724052649874,0.09603790238703921,0.0,0.007900670914045345,0.08730722409160394,0.15334989937216306,0.8643121965600912
bleu3,1516.0,0.05937062384269866,0.0834295643755584,0.0,5.647050663819558e-104,8.869436163644264e-103,0.09978131528985697,0.8127937802851734
bleu4,1516.0,0.03441261328743252,0.06954454451217174,0.0,3.7531479177786286e-156,5.81474064873044e-155,0.05492113857857506,0.7522135016840221
contextual_relevancy,1516.0,0.7585924358247081,0.2616612706439877,0.05,0.5714285714285714,0.8461538461538461,1.0,1.0
factual_correctness,1516.0,0.6044230534912446,0.2058851020506681,0.09277793749859806,0.4230846394816098,0.6514278534865798,0.7747824949556065,1.0
faithfulness,1516.0,0.8536724672278763,0.30258398412653953,0.0,1.0,1.0,1.0,1.0
hallucination,1516.0,0.46174142480211083,0.4986986382321515,0.0,0.0,0.0,1.0,1.0
rouge1,1516.0,0.2992785050139878,0.11686966676005031,0.0,0.22580645161290322,0.29758481886141464,0.37142857142857144,0.9387755102040817
rouge2,1516.0,0.10739275394382146,0.093492542329241,0.0,0.03846153846153846,0.0916083916083916,0.1568627450980392,0.851063829787234
rougeL,1516.0,0.2313089573796156,0.10322947968439837,0.0,0.16666666666666666,0.21998185300937595,0.2857142857142857,0.9387755102040817
