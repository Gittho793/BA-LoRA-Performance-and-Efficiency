,count,mean,std,min,25%,50%,75%,max
answer_relevancy,255.0,0.9476377217553688,0.1523183973817492,0.0,1.0,1.0,1.0,1.0
bert_f1,255.0,0.8569305969219582,0.028504336365218413,0.7233883142471313,0.843104362487793,0.8570224642753601,0.8726052045822144,0.9865767359733582
bert_precision,255.0,0.8690729307193382,0.029306310197227296,0.7555491924285889,0.85154989361763,0.8681674003601074,0.8873933255672455,0.9929955005645752
bert_recall,255.0,0.8456949759932125,0.03459029584955814,0.6173889636993408,0.828452855348587,0.8468555212020874,0.8644190430641174,0.980240523815155
bleu1,255.0,0.2178858542630079,0.11487025250030129,0.0,0.13995158924157455,0.21271640466194733,0.29103041228046767,0.8143536762323635
bleu2,255.0,0.11695494005307076,0.09981674682325849,0.0,0.04316589835180218,0.10386961052679987,0.16996754031055178,0.6398166741645539
bleu3,255.0,0.07252790532612148,0.08924432313372,0.0,3.2732196267364575e-103,0.05206492600217035,0.12468060727525765,0.5726519641750293
bleu4,255.0,0.043683622698899346,0.07640017210755495,0.0,2.3834050046708265e-155,1.3661746186555576e-78,0.08033055450889989,0.5176799652410778
contextual_relevancy,255.0,0.7827757279188333,0.20875183770748873,0.2,0.6666666666666666,0.8181818181818182,1.0,1.0
factual_correctness,255.0,0.687568476041596,0.21055695102002456,0.0679178699175393,0.5912010009850706,0.7528705965016396,0.8418249646866693,1.0
faithfulness,255.0,0.8755700798838053,0.25208460845747166,0.0,1.0,1.0,1.0,1.0
hallucination,255.0,0.43137254901960786,0.4962418590849061,0.0,0.0,0.0,1.0,1.0
rouge1,255.0,0.3122849248702902,0.12058882973168449,0.03076923076923077,0.23282514586862413,0.3157894736842105,0.38196555217831807,0.962962962962963
rouge2,255.0,0.11777226303871231,0.1031953951793608,0.0,0.042105263157894736,0.09523809523809523,0.1710801393728223,0.7199999999999999
rougeL,255.0,0.24449641828174137,0.1124456887946129,0.03076923076923077,0.1645447219983884,0.23655913978494625,0.2966629996332967,0.888888888888889
