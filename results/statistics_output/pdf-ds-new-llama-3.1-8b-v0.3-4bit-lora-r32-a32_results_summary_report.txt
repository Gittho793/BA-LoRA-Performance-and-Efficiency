EVALUATION METRICS SUMMARY REPORT: pdf-ds-new-llama-3.1-8b-v0.3-4bit-lora-r32-a32_results.json
================================================================================

Total number of evaluations: 255

Quality Metrics:
---------------
ANSWER_RELEVANCY     | Mean: 0.9633 | Std: 0.1143 | Range: [0.3333, 1.0000]
FAITHFULNESS         | Mean: 0.8500 | Std: 0.2832 | Range: [0.0000, 1.0000]
CONTEXTUAL_RELEVANCY | Mean: 0.8158 | Std: 0.1896 | Range: [0.2222, 1.0000]
HALLUCINATION        | Mean: 0.4980 | Std: 0.5000 | Range: [0.0000, 1.0000]
FACTUAL_CORRECTNESS  | Mean: 0.6815 | Std: 0.1966 | Range: [0.0698, 1.0000]

BLEU Scores:
-----------
BLEU1                | Mean: 0.2251 | Std: 0.1035 | Range: [0.0000, 0.6000]
BLEU2                | Mean: 0.1156 | Std: 0.0924 | Range: [0.0000, 0.5382]
BLEU3                | Mean: 0.0689 | Std: 0.0849 | Range: [0.0000, 0.5023]
BLEU4                | Mean: 0.0408 | Std: 0.0730 | Range: [0.0000, 0.4742]

ROUGE Scores:
------------
ROUGE1               | Mean: 0.3066 | Std: 0.1047 | Range: [0.0000, 0.7586]
ROUGE2               | Mean: 0.1065 | Std: 0.0885 | Range: [0.0000, 0.6071]
ROUGEL               | Mean: 0.2371 | Std: 0.0984 | Range: [0.0000, 0.7586]

BERT Scores:
-----------
BERT_PRECISION       | Mean: 0.8637 | Std: 0.0264 | Range: [0.7708, 0.9347]
BERT_RECALL          | Mean: 0.8440 | Std: 0.0305 | Range: [0.6174, 0.9476]
BERT_F1              | Mean: 0.8535 | Std: 0.0245 | Range: [0.7234, 0.9328]

KEY INSIGHTS:
-------------
• Highest mean score: answer_relevancy (0.9633)
• Lowest mean score: rouge2 (0.1065)
• Most variable metric: hallucination (std: 0.5000)
• Least variable metric: bert_f1 (std: 0.0245)
