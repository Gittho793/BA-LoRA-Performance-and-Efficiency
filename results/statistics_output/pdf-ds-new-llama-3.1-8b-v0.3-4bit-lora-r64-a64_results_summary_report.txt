EVALUATION METRICS SUMMARY REPORT: pdf-ds-new-llama-3.1-8b-v0.3-4bit-lora-r64-a64_results.json
================================================================================

Total number of evaluations: 255

Quality Metrics:
---------------
ANSWER_RELEVANCY     | Mean: 0.9635 | Std: 0.1190 | Range: [0.0000, 1.0000]
FAITHFULNESS         | Mean: 0.8697 | Std: 0.2674 | Range: [0.0000, 1.0000]
CONTEXTUAL_RELEVANCY | Mean: 0.8162 | Std: 0.1943 | Range: [0.2222, 1.0000]
HALLUCINATION        | Mean: 0.4627 | Std: 0.4986 | Range: [0.0000, 1.0000]
FACTUAL_CORRECTNESS  | Mean: 0.7077 | Std: 0.1958 | Range: [0.0899, 1.0000]

BLEU Scores:
-----------
BLEU1                | Mean: 0.2215 | Std: 0.1059 | Range: [0.0000, 0.7273]
BLEU2                | Mean: 0.1134 | Std: 0.0972 | Range: [0.0000, 0.6606]
BLEU3                | Mean: 0.0684 | Std: 0.0871 | Range: [0.0000, 0.5820]
BLEU4                | Mean: 0.0403 | Std: 0.0737 | Range: [0.0000, 0.4692]

ROUGE Scores:
------------
ROUGE1               | Mean: 0.3103 | Std: 0.1054 | Range: [0.0080, 0.7407]
ROUGE2               | Mean: 0.1119 | Std: 0.0950 | Range: [0.0000, 0.6400]
ROUGEL               | Mean: 0.2426 | Std: 0.1021 | Range: [0.0053, 0.7407]

BERT Scores:
-----------
BERT_PRECISION       | Mean: 0.8674 | Std: 0.0301 | Range: [0.6990, 0.9547]
BERT_RECALL          | Mean: 0.8458 | Std: 0.0320 | Range: [0.6174, 0.9475]
BERT_F1              | Mean: 0.8562 | Std: 0.0272 | Range: [0.7234, 0.9389]

KEY INSIGHTS:
-------------
• Highest mean score: answer_relevancy (0.9635)
• Lowest mean score: rouge2 (0.1119)
• Most variable metric: hallucination (std: 0.4986)
• Least variable metric: bert_f1 (std: 0.0272)
