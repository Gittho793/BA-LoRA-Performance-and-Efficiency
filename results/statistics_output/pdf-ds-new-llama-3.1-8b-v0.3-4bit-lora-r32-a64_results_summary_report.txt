EVALUATION METRICS SUMMARY REPORT: pdf-ds-new-llama-3.1-8b-v0.3-4bit-lora-r32-a64_results.json
================================================================================

Total number of evaluations: 255

Quality Metrics:
---------------
ANSWER_RELEVANCY     | Mean: 0.9675 | Std: 0.1140 | Range: [0.0000, 1.0000]
FAITHFULNESS         | Mean: 0.8822 | Std: 0.2741 | Range: [0.0000, 1.0000]
CONTEXTUAL_RELEVANCY | Mean: 0.7925 | Std: 0.2034 | Range: [0.1538, 1.0000]
HALLUCINATION        | Mean: 0.4784 | Std: 0.4995 | Range: [0.0000, 1.0000]
FACTUAL_CORRECTNESS  | Mean: 0.7119 | Std: 0.2035 | Range: [0.0919, 1.0000]

BLEU Scores:
-----------
BLEU1                | Mean: 0.2165 | Std: 0.1075 | Range: [0.0000, 0.6296]
BLEU2                | Mean: 0.1124 | Std: 0.0931 | Range: [0.0000, 0.5823]
BLEU3                | Mean: 0.0680 | Std: 0.0820 | Range: [0.0000, 0.5493]
BLEU4                | Mean: 0.0401 | Std: 0.0701 | Range: [0.0000, 0.5226]

ROUGE Scores:
------------
ROUGE1               | Mean: 0.3071 | Std: 0.1076 | Range: [0.0083, 0.7018]
ROUGE2               | Mean: 0.1088 | Std: 0.0915 | Range: [0.0000, 0.6182]
ROUGEL               | Mean: 0.2386 | Std: 0.0988 | Range: [0.0083, 0.7018]

BERT Scores:
-----------
BERT_PRECISION       | Mean: 0.8669 | Std: 0.0299 | Range: [0.6673, 0.9411]
BERT_RECALL          | Mean: 0.8449 | Std: 0.0330 | Range: [0.6174, 0.9486]
BERT_F1              | Mean: 0.8554 | Std: 0.0279 | Range: [0.7101, 0.9434]

KEY INSIGHTS:
-------------
• Highest mean score: answer_relevancy (0.9675)
• Lowest mean score: rouge2 (0.1088)
• Most variable metric: hallucination (std: 0.4995)
• Least variable metric: bert_f1 (std: 0.0279)
