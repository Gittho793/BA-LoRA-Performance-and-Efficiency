EVALUATION METRICS SUMMARY REPORT: pdf-ds-new-llama-3.1-8b-v0.3-4bit-lora-r8-a16_results.json
================================================================================

Total number of evaluations: 255

Quality Metrics:
---------------
ANSWER_RELEVANCY     | Mean: 0.9648 | Std: 0.1234 | Range: [0.0000, 1.0000]
FAITHFULNESS         | Mean: 0.8778 | Std: 0.2593 | Range: [0.0000, 1.0000]
CONTEXTUAL_RELEVANCY | Mean: 0.8159 | Std: 0.1963 | Range: [0.1429, 1.0000]
HALLUCINATION        | Mean: 0.4863 | Std: 0.4998 | Range: [0.0000, 1.0000]
FACTUAL_CORRECTNESS  | Mean: 0.6646 | Std: 0.2246 | Range: [0.1024, 1.0000]

BLEU Scores:
-----------
BLEU1                | Mean: 0.2228 | Std: 0.1078 | Range: [0.0000, 0.7407]
BLEU2                | Mean: 0.1185 | Std: 0.0959 | Range: [0.0000, 0.6752]
BLEU3                | Mean: 0.0716 | Std: 0.0872 | Range: [0.0000, 0.6219]
BLEU4                | Mean: 0.0427 | Std: 0.0745 | Range: [0.0000, 0.5741]

ROUGE Scores:
------------
ROUGE1               | Mean: 0.3046 | Std: 0.1066 | Range: [0.0000, 0.7719]
ROUGE2               | Mean: 0.1102 | Std: 0.0885 | Range: [0.0000, 0.6545]
ROUGEL               | Mean: 0.2384 | Std: 0.0998 | Range: [0.0000, 0.7719]

BERT Scores:
-----------
BERT_PRECISION       | Mean: 0.8638 | Std: 0.0311 | Range: [0.6638, 0.9649]
BERT_RECALL          | Mean: 0.8448 | Std: 0.0311 | Range: [0.6174, 0.9489]
BERT_F1              | Mean: 0.8539 | Std: 0.0272 | Range: [0.7092, 0.9406]

KEY INSIGHTS:
-------------
• Highest mean score: answer_relevancy (0.9648)
• Lowest mean score: rouge2 (0.1102)
• Most variable metric: hallucination (std: 0.4998)
• Least variable metric: bert_f1 (std: 0.0272)
