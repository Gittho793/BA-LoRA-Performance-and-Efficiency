EVALUATION METRICS SUMMARY REPORT: pdf-ds-new-llama-3.1-8b-v0.3-4bit-lora-r16-a32_results.json
================================================================================

Total number of evaluations: 255

Quality Metrics:
---------------
ANSWER_RELEVANCY     | Mean: 0.9579 | Std: 0.1286 | Range: [0.0000, 1.0000]
FAITHFULNESS         | Mean: 0.8780 | Std: 0.2550 | Range: [0.0000, 1.0000]
CONTEXTUAL_RELEVANCY | Mean: 0.8179 | Std: 0.2006 | Range: [0.1667, 1.0000]
HALLUCINATION        | Mean: 0.4627 | Std: 0.4986 | Range: [0.0000, 1.0000]
FACTUAL_CORRECTNESS  | Mean: 0.7034 | Std: 0.2121 | Range: [0.0864, 1.0000]

BLEU Scores:
-----------
BLEU1                | Mean: 0.2217 | Std: 0.0974 | Range: [0.0000, 0.6071]
BLEU2                | Mean: 0.1170 | Std: 0.0897 | Range: [0.0000, 0.5611]
BLEU3                | Mean: 0.0713 | Std: 0.0835 | Range: [0.0000, 0.5291]
BLEU4                | Mean: 0.0433 | Std: 0.0728 | Range: [0.0000, 0.5028]

ROUGE Scores:
------------
ROUGE1               | Mean: 0.3068 | Std: 0.1015 | Range: [0.0286, 0.7241]
ROUGE2               | Mean: 0.1134 | Std: 0.0897 | Range: [0.0000, 0.6071]
ROUGEL               | Mean: 0.2387 | Std: 0.0961 | Range: [0.0176, 0.7241]

BERT Scores:
-----------
BERT_PRECISION       | Mean: 0.8654 | Std: 0.0285 | Range: [0.7649, 0.9459]
BERT_RECALL          | Mean: 0.8471 | Std: 0.0304 | Range: [0.6174, 0.9521]
BERT_F1              | Mean: 0.8558 | Std: 0.0251 | Range: [0.7234, 0.9490]

KEY INSIGHTS:
-------------
• Highest mean score: answer_relevancy (0.9579)
• Lowest mean score: rouge2 (0.1134)
• Most variable metric: hallucination (std: 0.4986)
• Least variable metric: bert_f1 (std: 0.0251)
