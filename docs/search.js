window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "src", "modulename": "src", "kind": "module", "doc": "<p>Source folder for the package including all submodules.</p>\n"}, {"fullname": "src.eval", "modulename": "src.eval", "kind": "module", "doc": "<p>Offline LLM Evaluation Pipeline against Ground Truth and expected output using DeepEval</p>\n"}, {"fullname": "src.eval.deepeval_openai", "modulename": "src.eval.deepeval_openai", "kind": "module", "doc": "<p>Use the deepeval library to evaluate predictions of an LLM with ground truth text and expected answers</p>\n"}, {"fullname": "src.eval.deepeval_openai.EVAL_MODEL", "modulename": "src.eval.deepeval_openai", "qualname": "EVAL_MODEL", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;deepeval.models.llms.openai_model.GPTModel object&gt;"}, {"fullname": "src.eval.deepeval_openai.integrate_deepeval_metrics", "modulename": "src.eval.deepeval_openai", "qualname": "integrate_deepeval_metrics", "kind": "function", "doc": "<p>Return a dict of DeepEval metrics, optionally including contextual relevancy (for RAG).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">include_contextual</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.deepeval_openai.evaluate_with_deepeval", "modulename": "src.eval.deepeval_openai", "qualname": "evaluate_with_deepeval", "kind": "function", "doc": "<p>Evaluate every <question, predicted-answer, expected-answer> triple\nindependently with DeepEval metrics.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">gt_texts</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">pred_texts</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">question_map</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">answer_map</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">retrieval_context</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval", "modulename": "src.eval.expanded_eval", "kind": "module", "doc": "<p>Offline LLM Evaluation Pipeline against Ground Truth and expected output using DeepEval</p>\n\n<p>This script reads ground-truth text files and expected answers generated by an LLM,\nprompts an LLM for predictions, and computes evaluation metrics using the deepeval library.</p>\n\n<p>Meant to be started from grid_eval.py</p>\n"}, {"fullname": "src.eval.expanded_eval.project_root", "modulename": "src.eval.expanded_eval", "qualname": "project_root", "kind": "variable", "doc": "<p></p>\n", "default_value": "$PWD"}, {"fullname": "src.eval.expanded_eval.logger", "modulename": "src.eval.expanded_eval", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.eval.expanded_eval (INFO)&gt;"}, {"fullname": "src.eval.expanded_eval.parse_args", "modulename": "src.eval.expanded_eval", "qualname": "parse_args", "kind": "function", "doc": "<p>Parse CLI arguments</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.load_question_json", "modulename": "src.eval.expanded_eval", "qualname": "load_question_json", "kind": "function", "doc": "<p>Load questions and answers from JSON file</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.build_prompts", "modulename": "src.eval.expanded_eval", "qualname": "build_prompts", "kind": "function", "doc": "<p>Build a structured dict mapping from filename to a dict with:</p>\n\n<ul>\n<li>intro: prompt intro text </li>\n<li>questions: list of numbered question dicts {\"number\": int, \"text\": str}</li>\n<li>outro: prompt outro (e.g. \"Antworten:\")</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">question_map</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.read_text_files", "modulename": "src.eval.expanded_eval", "qualname": "read_text_files", "kind": "function", "doc": "<p>Read all text files from a folder</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">folder</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.save_predictions", "modulename": "src.eval.expanded_eval", "qualname": "save_predictions", "kind": "function", "doc": "<p>Save predictions from the model with model name in filename</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">preds</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>, </span><span class=\"param\"><span class=\"n\">model_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">base_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;output/predictions&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.read_json", "modulename": "src.eval.expanded_eval", "qualname": "read_json", "kind": "function", "doc": "<p>Read predictions made by the model</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.cleanup", "modulename": "src.eval.expanded_eval", "qualname": "cleanup", "kind": "function", "doc": "<p>Based on <a href=\"https://github.com/vllm-project/vllm/issues/6544\">https://github.com/vllm-project/vllm/issues/6544</a></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.generate_predictions", "modulename": "src.eval.expanded_eval", "qualname": "generate_predictions", "kind": "function", "doc": "<p>Generate predictions using the model with comprehensive GPU memory monitoring</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span>, </span><span class=\"param\"><span class=\"n\">tokenizer</span>, </span><span class=\"param\"><span class=\"n\">inputs</span>, </span><span class=\"param\"><span class=\"n\">args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.evaluate_optimized_deepeval", "modulename": "src.eval.expanded_eval", "qualname": "evaluate_optimized_deepeval", "kind": "function", "doc": "<p>Optimized evaluate function with memory management for BERT score\nModified to work with deepeval JSON structure:\n{\n  \"filename.txt\": [\n    {\n      \"question\": \"...\",\n      \"expected\": \"...\", \n      \"predicted\": \"...\",\n      \"metrics\": {...}\n    },\n    ...\n  ]\n}</p>\n\n<p>Args:\n    deepeval_data: Dictionary with the structure shown above\n    args: Argument object with evaluation flags (bleu, rouge, bert_score, etc.)</p>\n\n<p>Returns:\n    Dictionary with same structure but additional computed metrics per question</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">deepeval_data</span>, </span><span class=\"param\"><span class=\"n\">args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.aggregate_question_metrics", "modulename": "src.eval.expanded_eval", "qualname": "aggregate_question_metrics", "kind": "function", "doc": "<p>Aggregate metrics across all questions to get file-level and overall statistics</p>\n\n<p>Args:\n    results: Output from evaluate_optimized_deepeval</p>\n\n<p>Returns:\n    Dictionary with aggregated metrics</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">results</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.save_evaluation_results", "modulename": "src.eval.expanded_eval", "qualname": "save_evaluation_results", "kind": "function", "doc": "<p>Save evaluation results to JSON file</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">results</span>, </span><span class=\"param\"><span class=\"n\">aggregated</span>, </span><span class=\"param\"><span class=\"n\">output_file</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.expanded_eval.main", "modulename": "src.eval.expanded_eval", "qualname": "main", "kind": "function", "doc": "<p>Main function to run the evaluation</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.generate_goldens_openapi", "modulename": "src.eval.generate_goldens_openapi", "kind": "module", "doc": "<p>Generate expected answers for the questions posed via OpenAI API</p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.MAX_RETRIES", "modulename": "src.eval.generate_goldens_openapi", "qualname": "MAX_RETRIES", "kind": "variable", "doc": "<p></p>\n", "default_value": "5"}, {"fullname": "src.eval.generate_goldens_openapi.INITIAL_DELAY", "modulename": "src.eval.generate_goldens_openapi", "qualname": "INITIAL_DELAY", "kind": "variable", "doc": "<p></p>\n", "default_value": "1"}, {"fullname": "src.eval.generate_goldens_openapi.MAX_DELAY", "modulename": "src.eval.generate_goldens_openapi", "qualname": "MAX_DELAY", "kind": "variable", "doc": "<p></p>\n", "default_value": "60"}, {"fullname": "src.eval.generate_goldens_openapi.CHUNK_SIZE", "modulename": "src.eval.generate_goldens_openapi", "qualname": "CHUNK_SIZE", "kind": "variable", "doc": "<p></p>\n", "default_value": "3000"}, {"fullname": "src.eval.generate_goldens_openapi.MIN_TEXT_LENGTH", "modulename": "src.eval.generate_goldens_openapi", "qualname": "MIN_TEXT_LENGTH", "kind": "variable", "doc": "<p></p>\n", "default_value": "100"}, {"fullname": "src.eval.generate_goldens_openapi.QuestionAnswer", "modulename": "src.eval.generate_goldens_openapi", "qualname": "QuestionAnswer", "kind": "class", "doc": "<p>Represents a question, its corresponding answer, and additional data.</p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.QuestionAnswer.__init__", "modulename": "src.eval.generate_goldens_openapi", "qualname": "QuestionAnswer.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">question</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">answer</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">difficulty</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">topic</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">source_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "src.eval.generate_goldens_openapi.QuestionAnswer.question", "modulename": "src.eval.generate_goldens_openapi", "qualname": "QuestionAnswer.question", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.eval.generate_goldens_openapi.QuestionAnswer.answer", "modulename": "src.eval.generate_goldens_openapi", "qualname": "QuestionAnswer.answer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.eval.generate_goldens_openapi.QuestionAnswer.difficulty", "modulename": "src.eval.generate_goldens_openapi", "qualname": "QuestionAnswer.difficulty", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.eval.generate_goldens_openapi.QuestionAnswer.topic", "modulename": "src.eval.generate_goldens_openapi", "qualname": "QuestionAnswer.topic", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.eval.generate_goldens_openapi.QuestionAnswer.source_file", "modulename": "src.eval.generate_goldens_openapi", "qualname": "QuestionAnswer.source_file", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.eval.generate_goldens_openapi.TextProcessor", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextProcessor", "kind": "class", "doc": "<p>Processes text files for question-answer pairs.</p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.TextProcessor.logger", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextProcessor.logger", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.TextProcessor.extract_text_from_file", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextProcessor.extract_text_from_file", "kind": "function", "doc": "<p>Extract text from a .txt file</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">txt_path</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.generate_goldens_openapi.TextProcessor.chunk_text", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextProcessor.chunk_text", "kind": "function", "doc": "<p>Chunk text into manageable pieces for the API.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">chunk_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">3000</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.generate_goldens_openapi.OpenAIQuestionGenerator", "modulename": "src.eval.generate_goldens_openapi", "qualname": "OpenAIQuestionGenerator", "kind": "class", "doc": "<p>Generates question-answer pairs using OpenAI GPT-4.1-mini.</p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.OpenAIQuestionGenerator.__init__", "modulename": "src.eval.generate_goldens_openapi", "qualname": "OpenAIQuestionGenerator.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">api_key</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "src.eval.generate_goldens_openapi.OpenAIQuestionGenerator.client", "modulename": "src.eval.generate_goldens_openapi", "qualname": "OpenAIQuestionGenerator.client", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.OpenAIQuestionGenerator.logger", "modulename": "src.eval.generate_goldens_openapi", "qualname": "OpenAIQuestionGenerator.logger", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.OpenAIQuestionGenerator.generate_questions", "modulename": "src.eval.generate_goldens_openapi", "qualname": "OpenAIQuestionGenerator.generate_questions", "kind": "function", "doc": "<p>Generate the questions for evaluation from the provided text.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">source_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"o\">.</span><span class=\"n\">generate_goldens_openapi</span><span class=\"o\">.</span><span class=\"n\">QuestionAnswer</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.generate_goldens_openapi.TextQuestionProcessor", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextQuestionProcessor", "kind": "class", "doc": "<p>Main processor to handle directories of text files, generate qa pairs and save json.</p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.TextQuestionProcessor.__init__", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextQuestionProcessor.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">api_key</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "src.eval.generate_goldens_openapi.TextQuestionProcessor.text_processor", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextQuestionProcessor.text_processor", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.TextQuestionProcessor.question_generator", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextQuestionProcessor.question_generator", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.TextQuestionProcessor.logger", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextQuestionProcessor.logger", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.generate_goldens_openapi.TextQuestionProcessor.process_directory", "modulename": "src.eval.generate_goldens_openapi", "qualname": "TextQuestionProcessor.process_directory", "kind": "function", "doc": "<p>Process all .txt files in the given directory and generate question-answer pairs.\nSaves results to output_file in JSON format.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">directory_path</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span>, </span><span class=\"param\"><span class=\"n\">output_file</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.generate_goldens_openapi.setup_logging", "modulename": "src.eval.generate_goldens_openapi", "qualname": "setup_logging", "kind": "function", "doc": "<p>Setup logging configuration</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">log_level</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;INFO&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.generate_goldens_openapi.main", "modulename": "src.eval.generate_goldens_openapi", "qualname": "main", "kind": "function", "doc": "<p>Main entry point for the script</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.grid_eval", "modulename": "src.eval.grid_eval", "kind": "module", "doc": "<p>Evaluate multiple models from one directory.</p>\n"}, {"fullname": "src.eval.grid_eval.project_root", "modulename": "src.eval.grid_eval", "qualname": "project_root", "kind": "variable", "doc": "<p></p>\n", "default_value": "$PWD"}, {"fullname": "src.eval.grid_eval.BASE_DIR", "modulename": "src.eval.grid_eval", "qualname": "BASE_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;/cluster/unslothLora/Llama&#x27;"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa", "modulename": "src.eval.mmlu_superglue_truthfulqa", "kind": "module", "doc": "<p>Comprehensive script for evaluating LLMs using Unsloth with MMLU and SuperGLUE benchmarks.</p>\n\n<p>This script demonstrates:</p>\n\n<ol>\n<li>Loading a fine-tuned model with Unsloth and LoRA adapters</li>\n<li>Evaluating on MMLU benchmark using LM Evaluation Harness</li>\n<li>Evaluating on SuperGLUE benchmark</li>\n</ol>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.logger", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.eval.mmlu_superglue_truthfulqa (INFO)&gt;"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.parse_args", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "parse_args", "kind": "function", "doc": "<p>Parse CLI arguments</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator", "kind": "class", "doc": "<p>Main class for evaluating Unsloth fine-tuned models</p>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.__init__", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.__init__", "kind": "function", "doc": "<p>Initialize the evaluator</p>\n\n<p>Args:\n    model_name: Base model name (e.g., \"unsloth/Meta-Llama-3.1-8B-Instruct\")\n    adapter_path: Path to LoRA adapter if using fine-tuned model\n    max_seq_length: Maximum sequence length\n    load_in_4bit: Whether to load model in 4-bit quantization\n    use_cache: Whether to use caching for evaluation</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">adapter_path</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">max_seq_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">2048</span>,</span><span class=\"param\">\t<span class=\"n\">load_in_4bit</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">use_cache</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.model_name", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.model_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.adapter_path", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.adapter_path", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.max_seq_length", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.max_seq_length", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.load_in_4bit", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.load_in_4bit", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.use_cache", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.use_cache", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.model", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.model", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.tokenizer", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.tokenizer", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.results", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.results", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.load_model", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.load_model", "kind": "function", "doc": "<p>Load the model with Unsloth optimizations</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.evaluate_mmlu", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.evaluate_mmlu", "kind": "function", "doc": "<p>Evaluate model on MMLU benchmark using LM Evaluation Harness</p>\n\n<p>Args:\n    num_fewshot: Number of few-shot examples (typically 5 for MMLU)\n    limit: Limit number of examples for testing (None for full evaluation)\n    batch_size: Batch size for evaluation (\"auto\" for automatic)</p>\n\n<p>Returns:\n    Dictionary containing evaluation results</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">num_fewshot</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">limit</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.evaluate_superglue", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.evaluate_superglue", "kind": "function", "doc": "<p>Evaluate model on SuperGLUE benchmark</p>\n\n<p>Args:\n    num_fewshot: Number of few-shot examples (typically 0-5 for SuperGLUE tasks)\n    limit: Limit number of examples for testing\n    batch_size: Batch size for evaluation</p>\n\n<p>Returns:\n    Dictionary containing evaluation results</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">num_fewshot</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">limit</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.evaluate_truthfulqa", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.evaluate_truthfulqa", "kind": "function", "doc": "<p>Evaluate model on TruthfulQA benchmark</p>\n\n<p>Args:\n    num_fewshot: Number of few-shot examples (typically 0 for TruthfulQA)\n    limit: Limit number of examples for testing\n    batch_size: Batch size for evaluation\n    tasks: Specific TruthfulQA tasks to run (None for all)</p>\n\n<p>Returns:\n    Dictionary containing evaluation results</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">num_fewshot</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">limit</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;auto&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">tasks</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.UnslothEvaluator.save_results", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "UnslothEvaluator.save_results", "kind": "function", "doc": "<p>Save evaluation results to file</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">filepath</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.main", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "main", "kind": "function", "doc": "<p>Main execution function</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.setup_environment", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "setup_environment", "kind": "function", "doc": "<p>Set up the evaluation environment</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.mmlu_superglue_truthfulqa.get_available_tasks", "modulename": "src.eval.mmlu_superglue_truthfulqa", "qualname": "get_available_tasks", "kind": "function", "doc": "<p>Get list of available evaluation tasks</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.rag_eval", "modulename": "src.eval.rag_eval", "kind": "module", "doc": "<p>Evaluate RAG pipeline results using the same metrics as expanded_eval.py</p>\n"}, {"fullname": "src.eval.rag_eval.project_root", "modulename": "src.eval.rag_eval", "qualname": "project_root", "kind": "variable", "doc": "<p></p>\n", "default_value": "$PWD"}, {"fullname": "src.eval.rag_eval.convert_rag_to_deepeval_format", "modulename": "src.eval.rag_eval", "qualname": "convert_rag_to_deepeval_format", "kind": "function", "doc": "<p>Convert RAG results to the same format as expanded_eval.py output</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">rag_results</span>, </span><span class=\"param\"><span class=\"n\">question_map</span>, </span><span class=\"param\"><span class=\"n\">answer_map</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.rag_eval.extract_retrieval_context", "modulename": "src.eval.rag_eval", "qualname": "extract_retrieval_context", "kind": "function", "doc": "<p>Extract retrieval context from RAG results in the format expected by deepeval_openai</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">rag_results</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.rag_eval.main", "modulename": "src.eval.rag_eval", "qualname": "main", "kind": "function", "doc": "<p>Main function to evaluate RAG results using specified metrics.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization", "modulename": "src.eval.visualization", "kind": "module", "doc": "<p>Visualization module for evaluation results.</p>\n"}, {"fullname": "src.eval.visualization.boxplot_analyze_results", "modulename": "src.eval.visualization.boxplot_analyze_results", "kind": "module", "doc": "<p>Analyze results JSON and save summaries + boxplots.</p>\n\n<p>Usage:\n  # Single file (unchanged behavior)\n  python analyze_results.py /path/to/<results>.json</p>\n\n<p># NEW: Directory mode (loads all json files whose basename starts with \"pdf\")\n  python analyze_results.py /path/to/dir</p>\n\n<p>Very similar to violin_analyze_results.py but uses boxplots instead of violin plots.\nCould've imported but no time so copied it</p>\n\n<p>Dependencies: pandas, matplotlib, numpy</p>\n"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.flatten_records", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "flatten_records", "kind": "function", "doc": "<p>Turn the JSON structure into a flat table of rows (one per Q/A item).\nHandles:</p>\n\n<ul>\n<li>data['detailed_results'] = { source_file: [ { ... item ... }, ... ], ... }</li>\n<li>'existing_metrics': { metric_name: {'score': float, ...}, ... }</li>\n<li>any top-level numeric fields in each item (e.g., bleu1, rouge1, bert_f1, ...)</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.numeric_columns", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "numeric_columns", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.make_output_paths_for_file", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "make_output_paths_for_file", "kind": "function", "doc": "<p>Build the output directory two levels up from the input file path:\n    ../../results/pictures/{file_stem}/\nand the files within it.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_json</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.make_output_paths_for_dir", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "make_output_paths_for_dir", "kind": "function", "doc": "<p>Build the output directory two levels up from the directory path:\n    ../../results/pictures/{dir_basename}_comparative_pdf/</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.save_summaries", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "save_summaries", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>, </span><span class=\"param\"><span class=\"n\">out_paths</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.save_boxplots", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "save_boxplots", "kind": "function", "doc": "<p>Save one boxplot per metric into individual PNG files in out_dir.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>, </span><span class=\"param\"><span class=\"n\">out_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.pretty_run_label", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "pretty_run_label", "kind": "function", "doc": "<p>Normalize run labels for comparative plots:</p>\n\n<ul>\n<li>If contains 'Meta-Llama' -> 'Base'</li>\n<li>Else if contains 'RAG' -> 'RAG'</li>\n<li>Else if ends with a<digits>-r<digits> (optionally followed by _results) -> that suffix</li>\n<li>Else -> original name</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.sort_labels_numerically", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "sort_labels_numerically", "kind": "function", "doc": "<p>Sorts run labels in a human-friendly numeric order.\nE.g., \"a8-r2\" will come before \"a128-r2\".\nFalls back to plain string comparison if no numbers are present.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">labels</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.save_combined_summaries", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "save_combined_summaries", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df_all</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">out_paths</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">run_col</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;run&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.save_comparative_boxplots", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "save_comparative_boxplots", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df_all</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">out_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">run_col</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;run&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.load_json_safely", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "load_json_safely", "kind": "function", "doc": "<p>Load one results JSON into a DataFrame with error handling. Returns (run_label, df).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.process_single_file", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "process_single_file", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_json</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.process_directory", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "process_directory", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.boxplot_analyze_results.main", "modulename": "src.eval.visualization.boxplot_analyze_results", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency", "modulename": "src.eval.visualization.efficiency", "kind": "module", "doc": "<p>Robust analyzer for GPU usage logs across a directory tree.</p>\n\n<p>Fixes vs v1:</p>\n\n<ul>\n<li>Accepts <em>any</em> training file whose filename starts with \"gpu_usage\" (any extension) but\ndoes NOT contain \"generation\". (E.g., gpu_usage, gpu_usage.txt, gpu_usage.log)</li>\n<li>Accepts <em>any</em> generation file that contains both \"generation\" and \"gpu_usage\" in the filename.</li>\n<li>Supports decimal commas (e.g., \"26,82 minutes\") and flexible wording like\n\"used in generation\" or \"inference\". Also tolerates \":\" vs \"=\" after labels,\nand \"GB/GiB\" units.</li>\n<li>Adds clear console diagnostics if no values were parsed for a folder.</li>\n<li>Saves a CSV summary next to the plots.</li>\n</ul>\n\n<p>Usage remains the same:\n    python analyze_gpu_usage.py --root /path/to/root [--vram-metric gb|pct|phase-gb] [--gen-choice max-minutes|newest]</p>\n"}, {"fullname": "src.eval.visualization.efficiency.project_root", "modulename": "src.eval.visualization.efficiency", "qualname": "project_root", "kind": "variable", "doc": "<p></p>\n", "default_value": "$PWD"}, {"fullname": "src.eval.visualization.efficiency.is_training_file", "modulename": "src.eval.visualization.efficiency", "qualname": "is_training_file", "kind": "function", "doc": "<p>Check if the filename indicates a training GPU usage log file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">fn</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.is_generation_file", "modulename": "src.eval.visualization.efficiency", "qualname": "is_generation_file", "kind": "function", "doc": "<p>Check if the filename indicates a inference GPU usage log file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">fn</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.parse_num", "modulename": "src.eval.visualization.efficiency", "qualname": "parse_num", "kind": "function", "doc": "<p>Parse a numeric string that may use '.' or ',' as decimal separator.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">s</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.NUM", "modulename": "src.eval.visualization.efficiency", "qualname": "NUM", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;([0-9]+(?:[.,][0-9]+)?)&#x27;"}, {"fullname": "src.eval.visualization.efficiency.RE_TRAIN_MIN", "modulename": "src.eval.visualization.efficiency", "qualname": "RE_TRAIN_MIN", "kind": "variable", "doc": "<p></p>\n", "default_value": "re.compile(&#x27;([0-9]+(?:[.,][0-9]+)?)\\\\s*(?:min(?:ute)?s?)\\\\s+used\\\\s+(?:for|in)\\\\s+training&#x27;, re.IGNORECASE)"}, {"fullname": "src.eval.visualization.efficiency.RE_GEN_MIN", "modulename": "src.eval.visualization.efficiency", "qualname": "RE_GEN_MIN", "kind": "variable", "doc": "<p></p>\n", "default_value": "re.compile(&#x27;([0-9]+(?:[.,][0-9]+)?)\\\\s*(?:min(?:ute)?s?)\\\\s+used\\\\s+(?:for|in)\\\\s+(?:generation|inference)&#x27;, re.IGNORECASE)"}, {"fullname": "src.eval.visualization.efficiency.RE_PEAK_GB", "modulename": "src.eval.visualization.efficiency", "qualname": "RE_PEAK_GB", "kind": "variable", "doc": "<p></p>\n", "default_value": "re.compile(&#x27;Peak\\\\s*reserved\\\\s*memory\\\\s*[:=]\\\\s*([0-9]+(?:[.,][0-9]+)?)\\\\s*(?:G?i?B)&#x27;, re.IGNORECASE)"}, {"fullname": "src.eval.visualization.efficiency.RE_PEAK_PCT", "modulename": "src.eval.visualization.efficiency", "qualname": "RE_PEAK_PCT", "kind": "variable", "doc": "<p></p>\n", "default_value": "re.compile(&#x27;Peak\\\\s*reserved\\\\s*memory\\\\s*%?\\\\s*of\\\\s*max\\\\s*memory\\\\s*[:=]\\\\s*([0-9]+(?:[.,][0-9]+)?)\\\\s*%&#x27;, re.IGNORECASE)"}, {"fullname": "src.eval.visualization.efficiency.RE_PEAK_GEN_GB", "modulename": "src.eval.visualization.efficiency", "qualname": "RE_PEAK_GEN_GB", "kind": "variable", "doc": "<p></p>\n", "default_value": "re.compile(&#x27;Peak\\\\s*reserved\\\\s*memory\\\\s*(?:for\\\\s+generation|for\\\\s+inference)\\\\s*[:=]\\\\s*([0-9]+(?:[.,][0-9]+)?)\\\\s*(?:G?i?B)&#x27;, re.IGNORECASE)"}, {"fullname": "src.eval.visualization.efficiency.RE_PEAK_TRAIN_GB", "modulename": "src.eval.visualization.efficiency", "qualname": "RE_PEAK_TRAIN_GB", "kind": "variable", "doc": "<p></p>\n", "default_value": "re.compile(&#x27;Peak\\\\s*reserved\\\\s*memory\\\\s*(?:for\\\\s+training)\\\\s*[:=]\\\\s*([0-9]+(?:[.,][0-9]+)?)\\\\s*(?:G?i?B)&#x27;, re.IGNORECASE)"}, {"fullname": "src.eval.visualization.efficiency.FolderStats", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats", "kind": "class", "doc": "<p>Statistics for a single folder.</p>\n"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.__init__", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">folder</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">train_minutes</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">gen_minutes</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">train_vram_gb</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">gen_vram_gb</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">train_vram_pct</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">gen_vram_pct</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">train_vram_for_phase_gb</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">gen_vram_for_phase_gb</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.folder", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.folder", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.train_minutes", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.train_minutes", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.gen_minutes", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.gen_minutes", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.train_vram_gb", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.train_vram_gb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.gen_vram_gb", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.gen_vram_gb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.train_vram_pct", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.train_vram_pct", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.gen_vram_pct", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.gen_vram_pct", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.train_vram_for_phase_gb", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.train_vram_for_phase_gb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "src.eval.visualization.efficiency.FolderStats.gen_vram_for_phase_gb", "modulename": "src.eval.visualization.efficiency", "qualname": "FolderStats.gen_vram_for_phase_gb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Optional[float]", "default_value": "None"}, {"fullname": "src.eval.visualization.efficiency.read_text", "modulename": "src.eval.visualization.efficiency", "qualname": "read_text", "kind": "function", "doc": "<p>Read text file with utf-8 encoding, ignoring errors.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.parse_training_file", "modulename": "src.eval.visualization.efficiency", "qualname": "parse_training_file", "kind": "function", "doc": "<p>parse a training gpu_usage file</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.parse_generation_file", "modulename": "src.eval.visualization.efficiency", "qualname": "parse_generation_file", "kind": "function", "doc": "<p>parse a inference gpu_usage file</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.gather_stats", "modulename": "src.eval.visualization.efficiency", "qualname": "gather_stats", "kind": "function", "doc": "<p>gather stats from all folders under root_dir</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">root_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">gen_choice</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"o\">.</span><span class=\"n\">visualization</span><span class=\"o\">.</span><span class=\"n\">efficiency</span><span class=\"o\">.</span><span class=\"n\">FolderStats</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.make_dataframe", "modulename": "src.eval.visualization.efficiency", "qualname": "make_dataframe", "kind": "function", "doc": "<p>Create a DataFrame from the gathered stats.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">stats</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"o\">.</span><span class=\"n\">visualization</span><span class=\"o\">.</span><span class=\"n\">efficiency</span><span class=\"o\">.</span><span class=\"n\">FolderStats</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.plot_grouped_bars", "modulename": "src.eval.visualization.efficiency", "qualname": "plot_grouped_bars", "kind": "function", "doc": "<p>plot grouped bar chart comparing v1 and v2 across x_labels</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">x_labels</span>,</span><span class=\"param\">\t<span class=\"n\">v1</span>,</span><span class=\"param\">\t<span class=\"n\">v2</span>,</span><span class=\"param\">\t<span class=\"n\">title</span>,</span><span class=\"param\">\t<span class=\"n\">ylabel</span>,</span><span class=\"param\">\t<span class=\"n\">legend_labels</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">&#39;Training&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;Generation&#39;</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">outfile</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.analyze", "modulename": "src.eval.visualization.efficiency", "qualname": "analyze", "kind": "function", "doc": "<p>Analyze GPU usage logs under root_dir and generate plots and CSV summary.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">root_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">gen_choice</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;max-minutes&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">vram_metric</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;gb&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">out_times</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;training_generation_times.png&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">out_vram</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;training_generation_vram.png&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">out_csv</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;gpu_usage_summary.csv&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.efficiency.main", "modulename": "src.eval.visualization.efficiency", "qualname": "main", "kind": "function", "doc": "<p>Main execution function for command-line usage.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin", "modulename": "src.eval.visualization.violin", "kind": "module", "doc": "<p>Analyze results JSON and save summaries + violin/bar plots.</p>\n\n<p>Usage:\n  # Single file\n  python analyze_results.py /path/to/<results>.json</p>\n\n<p># Directory mode (loads all json files whose basename starts with \"pdf\")\n  python analyze_results.py /path/to/dir</p>\n\n<p>Very similar to boxplot_analyze_results.py but uses violin plots instead of boxplots.\nCould've imported but no time so copied</p>\n\n<p>Dependencies: pandas, matplotlib, numpy</p>\n"}, {"fullname": "src.eval.visualization.violin.flatten_records", "modulename": "src.eval.visualization.violin", "qualname": "flatten_records", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.numeric_columns", "modulename": "src.eval.visualization.violin", "qualname": "numeric_columns", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.find_first_hallucination_col", "modulename": "src.eval.visualization.violin", "qualname": "find_first_hallucination_col", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.make_output_paths_for_file", "modulename": "src.eval.visualization.violin", "qualname": "make_output_paths_for_file", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_json</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.make_output_paths_for_dir", "modulename": "src.eval.visualization.violin", "qualname": "make_output_paths_for_dir", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.save_summaries", "modulename": "src.eval.visualization.violin", "qualname": "save_summaries", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>, </span><span class=\"param\"><span class=\"n\">out_paths</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.save_violins_all_metrics_except_halluc", "modulename": "src.eval.visualization.violin", "qualname": "save_violins_all_metrics_except_halluc", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>, </span><span class=\"param\"><span class=\"n\">out_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.save_hallucination_bar_raw", "modulename": "src.eval.visualization.violin", "qualname": "save_hallucination_bar_raw", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>, </span><span class=\"param\"><span class=\"n\">out_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.pretty_run_label", "modulename": "src.eval.visualization.violin", "qualname": "pretty_run_label", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.sort_labels_numerically", "modulename": "src.eval.visualization.violin", "qualname": "sort_labels_numerically", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">labels</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.save_comparative_violins_all_metrics_except_halluc", "modulename": "src.eval.visualization.violin", "qualname": "save_comparative_violins_all_metrics_except_halluc", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df_all</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">out_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">run_col</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;run&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.save_comparative_hallucination_bar_raw", "modulename": "src.eval.visualization.violin", "qualname": "save_comparative_hallucination_bar_raw", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df_all</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">out_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">run_col</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;run&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.load_json_safely", "modulename": "src.eval.visualization.violin", "qualname": "load_json_safely", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.process_single_file", "modulename": "src.eval.visualization.violin", "qualname": "process_single_file", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_json</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.process_directory", "modulename": "src.eval.visualization.violin", "qualname": "process_directory", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.violin.main", "modulename": "src.eval.visualization.violin", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer", "modulename": "src.eval.visualization.visualizer", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.eval.visualization.visualizer.project_root", "modulename": "src.eval.visualization.visualizer", "qualname": "project_root", "kind": "variable", "doc": "<p></p>\n", "default_value": "$PWD"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer", "kind": "class", "doc": "<p>Visualization tool for model evaluation results.\nHandles MMLU / SuperGLUE / TruthfulQA plus detailed evaluation metrics.</p>\n"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.__init__", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">results_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;results&#39;</span></span>)</span>"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.results_dir", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.results_dir", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.data", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.data", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Dict[str, Dict]"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.colors", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.colors", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.extract_model_name", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.extract_model_name", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">filename</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.parse_mmlu_stdout", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.parse_mmlu_stdout", "kind": "function", "doc": "<p>Parse MMLU results from stdout.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">stdout_text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.load_benchmark_data", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.load_benchmark_data", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.load_detailed_metrics_data", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.load_detailed_metrics_data", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.load_all_data", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.load_all_data", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.filter_models_by_type", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.filter_models_by_type", "kind": "function", "doc": "<p>Return only models whose name starts with <code>model_type</code> (e.g., 'txt', 'pdf').</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">Dict</span>, </span><span class=\"param\"><span class=\"n\">model_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.plot_mmlu_comparison", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.plot_mmlu_comparison", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">data_subset</span><span class=\"p\">:</span> <span class=\"n\">Dict</span>, </span><span class=\"param\"><span class=\"n\">title_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">filename_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.plot_superglue_comparison", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.plot_superglue_comparison", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">data_subset</span><span class=\"p\">:</span> <span class=\"n\">Dict</span>, </span><span class=\"param\"><span class=\"n\">title_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">filename_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.plot_truthfulqa_comparison", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.plot_truthfulqa_comparison", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">data_subset</span><span class=\"p\">:</span> <span class=\"n\">Dict</span>, </span><span class=\"param\"><span class=\"n\">title_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">filename_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.plot_detailed_metrics_comparison", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.plot_detailed_metrics_comparison", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">data_subset</span><span class=\"p\">:</span> <span class=\"n\">Dict</span>, </span><span class=\"param\"><span class=\"n\">title_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">filename_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.plot_comprehensive_comparison", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.plot_comprehensive_comparison", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">data_subset</span><span class=\"p\">:</span> <span class=\"n\">Dict</span>, </span><span class=\"param\"><span class=\"n\">title_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">filename_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.generate_summary_report", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.generate_summary_report", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">data_subset</span><span class=\"p\">:</span> <span class=\"n\">Dict</span>, </span><span class=\"param\"><span class=\"n\">title_suffix</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.EvaluationVisualizer.run_full_analysis", "modulename": "src.eval.visualization.visualizer", "qualname": "EvaluationVisualizer.run_full_analysis", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.eval.visualization.visualizer.main", "modulename": "src.eval.visualization.visualizer", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.rag", "modulename": "src.rag", "kind": "module", "doc": "<p>RAG (Retrieval-Augmented Generation) module for document retrieval and question answering.</p>\n"}, {"fullname": "src.rag.rag_pipeline", "modulename": "src.rag.rag_pipeline", "kind": "module", "doc": "<p>RAG Pipeline with GPU Memory Monitoring</p>\n"}, {"fullname": "src.rag.rag_pipeline.project_root", "modulename": "src.rag.rag_pipeline", "qualname": "project_root", "kind": "variable", "doc": "<p></p>\n", "default_value": "$PWD"}, {"fullname": "src.rag.rag_pipeline.logger", "modulename": "src.rag.rag_pipeline", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.rag.rag_pipeline (INFO)&gt;"}, {"fullname": "src.rag.rag_pipeline.StepStat", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat", "kind": "class", "doc": "<p>Statistics for a single monitored step.</p>\n"}, {"fullname": "src.rag.rag_pipeline.StepStat.__init__", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">label</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">start_time_s</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">end_time_s</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">runtime_s</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">baseline_reserved_gb</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">step_peak_reserved_gb</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">step_increment_gb</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">pct_of_max_total</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">pct_increment_of_max</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span>)</span>"}, {"fullname": "src.rag.rag_pipeline.StepStat.label", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.label", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.rag.rag_pipeline.StepStat.start_time_s", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.start_time_s", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "src.rag.rag_pipeline.StepStat.end_time_s", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.end_time_s", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "src.rag.rag_pipeline.StepStat.runtime_s", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.runtime_s", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "src.rag.rag_pipeline.StepStat.baseline_reserved_gb", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.baseline_reserved_gb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "src.rag.rag_pipeline.StepStat.step_peak_reserved_gb", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.step_peak_reserved_gb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "src.rag.rag_pipeline.StepStat.step_increment_gb", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.step_increment_gb", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "src.rag.rag_pipeline.StepStat.pct_of_max_total", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.pct_of_max_total", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "src.rag.rag_pipeline.StepStat.pct_increment_of_max", "modulename": "src.rag.rag_pipeline", "qualname": "StepStat.pct_increment_of_max", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor", "kind": "class", "doc": "<p>Per-step GPU memory monitor. Use with MonitoredComponent to instrument Haystack components.\nProduces both a .txt and a .json report.</p>\n"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.__init__", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">device_index</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.cuda", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.cuda", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.device_index", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.device_index", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.device_name", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.device_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.total_gb", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.total_gb", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.sections", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.sections", "kind": "variable", "doc": "<p></p>\n", "annotation": ": List[src.rag.rag_pipeline.StepStat]"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.session_started", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.session_started", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.section", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.section", "kind": "function", "doc": "<p>Context manager to measure a single step (e.g., 'rag:llm', 'index:document_embedder').\nResets CUDA peak stats inside the section to isolate the step.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">label</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.print_session_header", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.print_session_header", "kind": "function", "doc": "<p>Print the header for the GPU memory monitoring session.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">title</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;GPU MEMORY MONITORING&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.print_session_footer", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.print_session_footer", "kind": "function", "doc": "<p>Print the footer for the GPU memory monitoring session.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.rag.rag_pipeline.GPUMemoryMonitor.write_reports", "modulename": "src.rag.rag_pipeline", "qualname": "GPUMemoryMonitor.write_reports", "kind": "function", "doc": "<p>Write GPU memory monitoring reports to the specified output directory.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">output_dir</span><span class=\"p\">:</span> <span class=\"n\">pathlib</span><span class=\"o\">.</span><span class=\"n\">Path</span>,</span><span class=\"param\">\t<span class=\"n\">filename_prefix</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;gpu_memory_report&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">extra_meta</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.rag.rag_pipeline.MonitoredComponent", "modulename": "src.rag.rag_pipeline", "qualname": "MonitoredComponent", "kind": "class", "doc": "<p>Thin proxy for any Haystack component that intercepts .run() and measures GPU memory.</p>\n"}, {"fullname": "src.rag.rag_pipeline.MonitoredComponent.__init__", "modulename": "src.rag.rag_pipeline", "qualname": "MonitoredComponent.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">inner</span>, </span><span class=\"param\"><span class=\"n\">label</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">monitor</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">rag</span><span class=\"o\">.</span><span class=\"n\">rag_pipeline</span><span class=\"o\">.</span><span class=\"n\">GPUMemoryMonitor</span></span>)</span>"}, {"fullname": "src.rag.rag_pipeline.MonitoredComponent.run", "modulename": "src.rag.rag_pipeline", "qualname": "MonitoredComponent.run", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline", "kind": "class", "doc": "<p>RAG Pipeline with document indexing and querying capabilities.\nIntegrates GPU memory monitoring for key components.</p>\n"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.__init__", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.__init__", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;unsloth/Meta-Llama-3.1-8B-Instruct&#39;</span></span>)</span>"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.model_name", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.model_name", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.document_store", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.document_store", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.indexing_pipeline", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.indexing_pipeline", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.rag_pipeline", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.rag_pipeline", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.gpu_monitor", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.gpu_monitor", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.index_documents", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.index_documents", "kind": "function", "doc": "<p>Index documents from the given file paths.</p>\n\n<p>Args:\n    file_paths: List of paths to PDF or TXT files</p>\n\n<p>Returns:\n    Result of the indexing pipeline</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">file_paths</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.query", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.query", "kind": "function", "doc": "<p>Query the RAG pipeline with a question.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">question</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.get_answer", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.get_answer", "kind": "function", "doc": "<p>Get a simple answer string from the RAG pipeline.</p>\n\n<p>Args:\n    question: The question to ask\n    top_k: Number of documents to retrieve</p>\n\n<p>Returns:\n    Generated answer as string</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">question</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.rag.rag_pipeline.RAGPipeline.get_answer_and_retrieval", "modulename": "src.rag.rag_pipeline", "qualname": "RAGPipeline.get_answer_and_retrieval", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">question</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">top_k</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">keep_content_chars</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.rag.rag_pipeline.main", "modulename": "src.rag.rag_pipeline", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.train", "modulename": "src.train", "kind": "module", "doc": "<p>Training module for LoRA models on custom dataset</p>\n"}, {"fullname": "src.train.grid_train", "modulename": "src.train.grid_train", "kind": "module", "doc": "<p>Train a LLM with LoRA using different ranks and alphas. Alpha is either the same or double the rank.</p>\n"}, {"fullname": "src.train.grid_train.ranks", "modulename": "src.train.grid_train", "qualname": "ranks", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[int]", "default_value": "[4, 8, 16, 32, 64, 128]"}, {"fullname": "src.train.train", "modulename": "src.train.train", "kind": "module", "doc": "<p>Script to fine-tune an LLM with LoRA using different ranks and alphas. Meant to be started from grid_train.py</p>\n"}, {"fullname": "src.train.train.get_pretrained_model_and_tokenizer", "modulename": "src.train.train", "qualname": "get_pretrained_model_and_tokenizer", "kind": "function", "doc": "<p>Get a pretrained model and tokenizer for fine-tuning from Hugging Face.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">load_in_4bit</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>, </span><span class=\"param\"><span class=\"n\">load_in_8bit</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>, </span><span class=\"param\"><span class=\"n\">full_finetuning</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.train.train.get_lora_model", "modulename": "src.train.train", "qualname": "get_lora_model", "kind": "function", "doc": "<p>Get a LoRA model with specified parameters</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model</span>,</span><span class=\"param\">\t<span class=\"n\">lora_dropout</span><span class=\"o\">=</span><span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"s1\">&#39;none&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">use_gradient_checkpointing</span><span class=\"o\">=</span><span class=\"s1\">&#39;unsloth&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">use_rslora</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">loftq_config</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.train.train.get_alpaca_prompt", "modulename": "src.train.train", "qualname": "get_alpaca_prompt", "kind": "function", "doc": "<p>Return the alpaca style prompt for training</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.train.train.formatting_prompts_func", "modulename": "src.train.train", "qualname": "formatting_prompts_func", "kind": "function", "doc": "<p>Format dataset to Alpaca style with instruction, input, output</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">examples</span>, </span><span class=\"param\"><span class=\"n\">alpaca_prompt</span>, </span><span class=\"param\"><span class=\"n\">eos_token</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.train.train.get_train_args", "modulename": "src.train.train", "qualname": "get_train_args", "kind": "function", "doc": "<p>Hyperparameters recommendations from: <a href=\"https://docs.unsloth.ai/get-started/fine-tuning-guide#id-6.-training--evaluation\">https://docs.unsloth.ai/get-started/fine-tuning-guide#id-6.-training--evaluation</a></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">per_device_train_batch_size</span><span class=\"o\">=</span><span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">gradient_accumulation_steps</span><span class=\"o\">=</span><span class=\"mi\">4</span>,</span><span class=\"param\">\t<span class=\"n\">warmup_steps</span><span class=\"o\">=</span><span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">num_train_epochs</span><span class=\"o\">=</span><span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.0001</span>,</span><span class=\"param\">\t<span class=\"n\">fp16</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">bf16</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">logging_steps</span><span class=\"o\">=</span><span class=\"mi\">50</span>,</span><span class=\"param\">\t<span class=\"n\">optim</span><span class=\"o\">=</span><span class=\"s1\">&#39;adamw_8bit&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">output_dir</span><span class=\"o\">=</span><span class=\"s1\">&#39;outputs&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">3407</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.train.train.get_sfttrainer", "modulename": "src.train.train", "qualname": "get_sfttrainer", "kind": "function", "doc": "<p>Get a Supervised Fine-Tuning Trainer with specified args</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span>,</span><span class=\"param\">\t<span class=\"n\">formatted_dataset</span>,</span><span class=\"param\">\t<span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">dataset_text_field</span><span class=\"o\">=</span><span class=\"s1\">&#39;text&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">dataset_num_processes</span><span class=\"o\">=</span><span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">packing</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.train.train.main", "modulename": "src.train.train", "qualname": "main", "kind": "function", "doc": "<p>Main training function</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util", "modulename": "src.util", "kind": "module", "doc": "<p>Utility module for helpful functions and miscellaneous tools.</p>\n"}, {"fullname": "src.util.args", "modulename": "src.util.args", "kind": "module", "doc": "<p>Global constants and configurations for the project.</p>\n"}, {"fullname": "src.util.args.RANK", "modulename": "src.util.args", "qualname": "RANK", "kind": "variable", "doc": "<p></p>\n", "default_value": "16"}, {"fullname": "src.util.args.ALPHA", "modulename": "src.util.args", "qualname": "ALPHA", "kind": "variable", "doc": "<p></p>\n", "default_value": "16"}, {"fullname": "src.util.args.MODEL_NAME", "modulename": "src.util.args", "qualname": "MODEL_NAME", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;unsloth/Meta-Llama-3.1-8B-Instruct&#x27;"}, {"fullname": "src.util.args.PDF_DATA_PATH", "modulename": "src.util.args", "qualname": "PDF_DATA_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;../../data/splitted_pdfs/&#x27;"}, {"fullname": "src.util.args.PDF_GROUND_TRUTH_FILES", "modulename": "src.util.args", "qualname": "PDF_GROUND_TRUTH_FILES", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;../../data/raw_splitted_pdfs&#x27;"}, {"fullname": "src.util.args.PDF_OUTPUT_DIR", "modulename": "src.util.args", "qualname": "PDF_OUTPUT_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;../../../unslothLora/Llama/pdf-ds-new-llama-3.1-8b-v0.3-4bit-lora-r16-a16&#x27;"}, {"fullname": "src.util.args.TXT_DATA_PATH", "modulename": "src.util.args", "qualname": "TXT_DATA_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;../../data/splitted_txts/&#x27;"}, {"fullname": "src.util.args.TXT_GROUND_TRUTH_FILES", "modulename": "src.util.args", "qualname": "TXT_GROUND_TRUTH_FILES", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;../../data/raw_splitted_txt&#x27;"}, {"fullname": "src.util.args.TXT_OUTPUT_DIR", "modulename": "src.util.args", "qualname": "TXT_OUTPUT_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;../../../unslothLora/Llama/txt-ds-new-llama-3.1-8b-v0.3-4bit-lora-r16-a16&#x27;"}, {"fullname": "src.util.args.MAX_SEQ_LENGTH", "modulename": "src.util.args", "qualname": "MAX_SEQ_LENGTH", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int", "default_value": "4096"}, {"fullname": "src.util.args.TARGET_MODULES", "modulename": "src.util.args", "qualname": "TARGET_MODULES", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;q_proj&#x27;, &#x27;k_proj&#x27;, &#x27;v_proj&#x27;, &#x27;o_proj&#x27;, &#x27;gate_proj&#x27;, &#x27;up_proj&#x27;, &#x27;down_proj&#x27;]"}, {"fullname": "src.util.misc", "modulename": "src.util.misc", "kind": "module", "doc": "<p>Miscellaneous utility functions and classes.</p>\n"}, {"fullname": "src.util.misc.extract_by_chapter", "modulename": "src.util.misc.extract_by_chapter", "kind": "module", "doc": "<p>Extract text by chapter from PDFs using their Table of Contents (if available).\nSaves each chapter as a separate .txt file. If no TOC is found, saves the entire PDF as one .txt file.</p>\n"}, {"fullname": "src.util.misc.extract_by_chapter.PDF_PATH", "modulename": "src.util.misc.extract_by_chapter", "qualname": "PDF_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "PosixPath(&#x27;pdfs&#x27;)"}, {"fullname": "src.util.misc.extract_by_chapter.TXT_PATH", "modulename": "src.util.misc.extract_by_chapter", "qualname": "TXT_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "PosixPath(&#x27;txt_out4&#x27;)"}, {"fullname": "src.util.misc.extract_by_chapter.strip_page_numbers", "modulename": "src.util.misc.extract_by_chapter", "qualname": "strip_page_numbers", "kind": "function", "doc": "<p>Remove typical page\u2011number lines such as '123', '\u2011\u202f123\u202f\u2011', etc.\nAdjust the regex if your footer looks different.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.util.misc.extract_by_chapter.clean_text", "modulename": "src.util.misc.extract_by_chapter", "qualname": "clean_text", "kind": "function", "doc": "<p>Additional scrubbing: normalize Unicode quotes, collapse 3+ newlines, trim.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">raw</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.util.misc.extract_by_chapter.chapters_from_toc", "modulename": "src.util.misc.extract_by_chapter", "qualname": "chapters_from_toc", "kind": "function", "doc": "<p>Yield tuples: (chapter_title, start_page, end_page).\nIf the PDF has <em>no</em> bookmarks, fall back to None so we can do na\u00efve splitting later.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">doc</span><span class=\"p\">:</span> <span class=\"n\">pymupdf</span><span class=\"o\">.</span><span class=\"n\">Document</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Generator</span><span class=\"p\">[</span><span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.util.misc.extract_by_chapter.sanitize_filename", "modulename": "src.util.misc.extract_by_chapter", "qualname": "sanitize_filename", "kind": "function", "doc": "<p>Remove or replace characters that are invalid in filenames.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.util.misc.extract_by_chapter.get_clean_page_text", "modulename": "src.util.misc.extract_by_chapter", "qualname": "get_clean_page_text", "kind": "function", "doc": "<p>Extract text blocks, skipping top and bottom areas (header/footer).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">page</span>, </span><span class=\"param\"><span class=\"n\">header_margin</span><span class=\"o\">=</span><span class=\"mi\">70</span>, </span><span class=\"param\"><span class=\"n\">footer_margin</span><span class=\"o\">=</span><span class=\"mi\">70</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.util.misc.extract_by_chapter.unwrap_paragraphs", "modulename": "src.util.misc.extract_by_chapter", "qualname": "unwrap_paragraphs", "kind": "function", "doc": "<p>Merges lines inside paragraphs while preserving paragraph breaks.\nA paragraph is assumed to be separated by double newlines.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.util.misc.extract_by_chapter.main", "modulename": "src.util.misc.extract_by_chapter", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.misc.inference", "modulename": "src.util.misc.inference", "kind": "module", "doc": "<p>Inference module for local inference of LLMs</p>\n"}, {"fullname": "src.util.misc.inference.inference", "modulename": "src.util.misc.inference.inference", "kind": "module", "doc": "<p>Simply test the inference of a local LLM using unsloth FastLanguageModel.</p>\n"}, {"fullname": "src.util.misc.inference.inference.project_root", "modulename": "src.util.misc.inference.inference", "qualname": "project_root", "kind": "variable", "doc": "<p></p>\n", "default_value": "$PWD"}, {"fullname": "src.util.misc.json_formatter", "modulename": "src.util.misc.json_formatter", "kind": "module", "doc": "<p>Convert JSON files with question-answer pairs into a standardized format.\nNot necessary if meta-synthetic-data-kit is used correctly</p>\n"}, {"fullname": "src.util.misc.json_formatter.DATA_DIR", "modulename": "src.util.misc.json_formatter", "qualname": "DATA_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "PosixPath(&#x27;data&#x27;)"}, {"fullname": "src.util.misc.json_formatter.FORMATTED_DIR", "modulename": "src.util.misc.json_formatter", "qualname": "FORMATTED_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "PosixPath(&#x27;data/formatted&#x27;)"}, {"fullname": "src.util.misc.json_formatter.INSTRUCTION", "modulename": "src.util.misc.json_formatter", "qualname": "INSTRUCTION", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;Beantworte die folgende Frage.&#x27;"}, {"fullname": "src.util.misc.tokenize_tester", "modulename": "src.util.misc.tokenize_tester", "kind": "module", "doc": "<p>Test tokenization with sliding window approach and print decoded outputs.\nJust to ensure tokenization works as expected.</p>\n"}, {"fullname": "src.util.misc.tokenize_tester.project_root", "modulename": "src.util.misc.tokenize_tester", "qualname": "project_root", "kind": "variable", "doc": "<p></p>\n", "default_value": "$CLUSTER_USER_DIR"}, {"fullname": "src.util.misc.tokenize_tester.load_tokenizer", "modulename": "src.util.misc.tokenize_tester", "qualname": "load_tokenizer", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.misc.tokenize_tester.sliding_tokenize", "modulename": "src.util.misc.tokenize_tester", "qualname": "sliding_tokenize", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">examples</span>, </span><span class=\"param\"><span class=\"n\">tokenizer</span>, </span><span class=\"param\"><span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">256</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.misc.tokenize_tester.main", "modulename": "src.util.misc.tokenize_tester", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.statistics", "modulename": "src.util.statistics", "kind": "module", "doc": "<p>Statistics utilities.</p>\n"}, {"fullname": "src.util.statistics.agg_statistics", "modulename": "src.util.statistics.agg_statistics", "kind": "module", "doc": "<p>Accumulate statistics (mean, std, variance, count, min, max) for all metrics in the results JSON file.</p>\n"}, {"fullname": "src.util.statistics.agg_statistics.compute_confidence_interval", "modulename": "src.util.statistics.agg_statistics", "qualname": "compute_confidence_interval", "kind": "function", "doc": "<p>Compute confidence interval for a dataset</p>\n\n<p>Args:\n    data: numpy array or list of values\n    confidence: confidence level (default 0.95 for 95% CI)</p>\n\n<p>Returns:\n    tuple: (lower_bound, upper_bound)</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data</span>, </span><span class=\"param\"><span class=\"n\">confidence</span><span class=\"o\">=</span><span class=\"mf\">0.95</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.statistics.agg_statistics.compute_metrics_statistics", "modulename": "src.util.statistics.agg_statistics", "qualname": "compute_metrics_statistics", "kind": "function", "doc": "<p>Compute mean and std for all metrics in the results JSON file</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">json_file_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.statistics.agg_statistics.numpy_mode", "modulename": "src.util.statistics.agg_statistics", "qualname": "numpy_mode", "kind": "function", "doc": "<p>Compute the mode of a numpy array</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.statistics.agg_statistics.add_existing_metrics_to_aggregated", "modulename": "src.util.statistics.agg_statistics", "qualname": "add_existing_metrics_to_aggregated", "kind": "function", "doc": "<p>Extract only existing_metrics from detailed_results and add them to aggregated_metrics.overall</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">json_file_path</span>, </span><span class=\"param\"><span class=\"n\">confidence_level</span><span class=\"o\">=</span><span class=\"mf\">0.95</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.statistics.agg_statistics.process_directory", "modulename": "src.util.statistics.agg_statistics", "qualname": "process_directory", "kind": "function", "doc": "<p>Process all JSON files in a directory</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">directory_path</span>, </span><span class=\"param\"><span class=\"n\">output_dir</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.statistics.merge_deepeval_results", "modulename": "src.util.statistics.merge_deepeval_results", "kind": "module", "doc": "<p>Merge DeepEval results into traditional metrics results without re-running DeepEval (for RAG pipeline)</p>\n"}, {"fullname": "src.util.statistics.merge_deepeval_results.merge_deepeval_into_traditional", "modulename": "src.util.statistics.merge_deepeval_results", "qualname": "merge_deepeval_into_traditional", "kind": "function", "doc": "<p>Merge DeepEval metrics into traditional metrics results to match the expected structure</p>\n\n<p>Args:\n    deepeval_file: Path to deepeval results JSON file\n    traditional_file: Path to traditional metrics results JSON<br />\n    output_file: Output file path (optional, defaults to traditional_file)</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">deepeval_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">traditional_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">output_file</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.util.statistics.merge_deepeval_results.main", "modulename": "src.util.statistics.merge_deepeval_results", "qualname": "main", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();